# CS225 Assignment3 Exercise 4

### 4.2
To insert k new elements into a max-heap with n elements within $O(k+\log(n))$, our algorithm executes the following procedures:  
1. rearranges the k-elements into a max-heap structure, **which takes $O(k)$ time**.  
2. merge the max-heap with n elements and the newly-built max-heap with k elements, **which takes $O(\log(n))$ time, given that heaps are implemented using tree nodes (which implies that the algorithm doesn't need to spend time balancing the heap).

Hence in total our algorithm achieves the specified task within $O(k + \log(n))$ time.

***Justification of Procedure 1***  
The k-element max-heap is built with $sift-down$.  
The execution of inserting an arbitrary element at height $h$ takes the time complexity $O(h)$.
For finding the Time Complexity of building a heap, we must know the number of nodes having height $h$. Since at height h the heap can have at most $\lceil{\frac{k}{2^{h+1}}}\rceil$ thus the total complexity shall be 
$$
\begin{aligned}
\sum^{\log(k)}_{h = 0}(\frac{k}{2^{h+1}}\cdot O(h)) & = \sum^{\infty}_{h = 0}(\frac{k}{2^{h+1}}\cdot O(h)) \\
& = O(k \cdot \sum^{\infty}_{h = 0}{\frac{h}{2^h}})\\
\end{aligned}
$$

For x < 1, we have 
$$\sum_{n = 0}^\infty{x^n} = \frac{1}{1-x}$$
Take the derivative of both sides then multiply by 1, we get
$$\sum_{n = 0}^\infty{n\cdot x^n} = \frac{x}{(1-x)^2}$$
Thus 
$$\sum^\infty_{h=0}{\frac{h}{2^h}} = \frac{\frac12}{{\frac12}^2} = 2$$  
And further, 
$$build\_heap = O(k\cdot 2) = O(k)$$

*Justification of Procedure 2*  
We use a recursive approach to merge the two trees, which takes $O(\log(n))$ time.
The procedure can be described as follows:  
$$\begin{aligned}
&result \leftarrow {\rm Merge}(heap\_n, heap\_k)\\
&\qquad \boldsymbol{\rm IF}\ heap\_n.left = \boldsymbol{\rm  NONE}\ \boldsymbol{\rm \&}\ heap\_n.right = \boldsymbol{\rm NONE}\ \boldsymbol{\rm THEN}  \\
&\qquad \qquad result \leftarrow {\rm Insert}(heap\_n, heap\_k) \\
&\qquad \qquad \boldsymbol{\rm RETURN} \\

&\qquad \boldsymbol{\rm IF}\ heap\_k.left = \boldsymbol{\rm NONE}\ \boldsymbol{\rm \&}\ heap\_k.right = \boldsymbol{\rm NONE}\ \boldsymbol{\rm THEN}\\
&\qquad \qquad result \leftarrow {\rm Insert}(heap\_k, heap\_n) \\
&\qquad \qquad \boldsymbol{\rm RETURN} \\

&\qquad \boldsymbol{\rm IF}\ heap\_n.value > heap\_k.value\ \boldsymbol{\rm THEN} \\
&\qquad \qquad \boldsymbol{\rm LET}\ \begin{aligned} child\_1 & =heap\_n.left \\ child\_2 & =heap\_n.right\end{aligned} \ \ \boldsymbol{\rm IN\ PAR} \\
& \qquad \qquad \qquad heap\_n.left = {\rm Max}(child\_1.value, child\_2.value)\\
& \qquad \qquad \qquad heap\_n.right = {\rm Merge}({\rm Min}(child\_1.value, child\_2.value), heap\_k) \\
& \qquad \qquad \qquad \boldsymbol{\rm END\ PAR} \\
& \qquad \qquad  result := heap\_n \\
& \qquad \qquad  \boldsymbol{\rm RETURN} \\
& \qquad \boldsymbol{\rm END IF} \\

& \qquad \boldsymbol{\rm IF}\ heap\_n.value < heap\_k.value\ \boldsymbol{\rm THEN} \\
&\qquad \qquad \boldsymbol{\rm LET}\ \begin{aligned} child\_1 & =heap\_k.left \\ child\_2 & =heap\_k.right\end{aligned} \ \ \boldsymbol{\rm IN\ PAR} \\
& \qquad \qquad \qquad heap\_k.left = {\rm Max}(child\_1.value, child\_2.value)\\
& \qquad \qquad \qquad heap\_n.right = {\rm Merge}({\rm Min}(child\_1.value, child\_2.value), heap\_n) \\
& \qquad \qquad \qquad \boldsymbol{\rm END\ PAR} \\
& \qquad \qquad  result := heap\_k \\
& \qquad \qquad \boldsymbol{\rm RETURN} \\
& \qquad \boldsymbol{\rm END IF}
\end{aligned}$$ 

The bases cases (either heap_n or heap_k is a single-node heap) have time complexity $O(\log(n))$ in the node insertion.
For more complex cases where $heap\_n.value < heap\_k.value$ or $heap\_n.value > heap\_k.value$, the time complexity linear w.r.t the depth of the heap, i.e. $f= O(n)$.

Hence the complexity in total is $O(k + \log(n))$.





     
